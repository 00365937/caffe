{
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "",
  "priority": 1
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Instant Recognition with Caffe\n",
      "\n",
      "In this example we'll classify an image with the bundled CaffeNet model based on the network architecture of Krizhevsky et al. for ImageNet. We'll compare CPU and GPU operation then reach into the model to inspect features and the output.\n",
      "\n",
      "(These feature visualizations follow the DeCAF visualizations originally by Yangqing Jia.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, import required modules, set plotting parameters, and run `./scripts/download_model_binary.py models/bvlc_reference_caffenet` to get the pretrained CaffeNet model if it hasn't already been fetched."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "# Make sure that caffe is on the python path:\n",
      "caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
      "import sys\n",
      "sys.path.insert(0, caffe_root + 'python')\n",
      "\n",
      "import caffe\n",
      "\n",
      "plt.rcParams['figure.figsize'] = (10, 10)\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'\n",
      "\n",
      "import os\n",
      "if not os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
      "    print(\"Downloading pre-trained CaffeNet model...\")\n",
      "    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set Caffe to CPU mode, load the net in the test phase for inference, and configure input preprocessing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "caffe.set_mode_cpu()\n",
      "net = caffe.Net(caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt',\n",
      "                caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel',\n",
      "                caffe.TEST)\n",
      "\n",
      "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
      "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
      "transformer.set_transpose('data', (2,0,1))\n",
      "transformer.set_mean('data', np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)) # mean pixel\n",
      "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
      "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a simple classification. We'll set a batch of 50 to demonstrate batch processing, even though we'll only be classifying one image. (Note that the batch size can also be changed on-the-fly.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set net to batch size of 50\n",
      "net.blobs['data'].reshape(50,3,227,227)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feed in the image (with some preprocessing) and classify with a forward pass."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.blobs['data'].data[...] = transformer.preprocess('data', caffe.io.load_image(caffe_root + 'examples/images/cat.jpg'))\n",
      "out = net.forward()\n",
      "print(\"Predicted class is #{}.\".format(out['prob'][0].argmax()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What did the input look like?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(transformer.deprocess('data', net.blobs['data'].data[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Adorable, but was our classification correct?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load labels\n",
      "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
      "try:\n",
      "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
      "except:\n",
      "    !../data/ilsvrc12/get_ilsvrc_aux.sh\n",
      "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
      "\n",
      "# sort top k predictions from softmax output\n",
      "top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
      "print labels[top_k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Indeed! But how long did it take?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CPU mode\n",
      "net.forward()  # call once for allocation\n",
      "%timeit net.forward()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's a while, even for a batch size of 50 images. Let's switch to GPU mode."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# GPU mode\n",
      "caffe.set_device(0)\n",
      "caffe.set_mode_gpu()\n",
      "net.forward()  # call once for allocation\n",
      "%timeit net.forward()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Much better. Now let's look at the net in more detail.\n",
      "\n",
      "First, the layer features and their shapes (1 is the batch size, corresponding to the single input image in this example)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[(k, v.data.shape) for k, v in net.blobs.items()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The parameters and their shapes. The parameters are `net.params['name'][0]` while biases are `net.params['name'][1]`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[(k, v[0].data.shape) for k, v in net.params.items()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper functions for visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# take an array of shape (n, height, width) or (n, height, width, channels)\n",
      "# and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\n",
      "def vis_square(data, padsize=1, padval=0):\n",
      "    data -= data.min()\n",
      "    data /= data.max()\n",
      "    \n",
      "    # force the number of filters to be square\n",
      "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
      "    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
      "    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
      "    \n",
      "    # tile the filters into an image\n",
      "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
      "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
      "    \n",
      "    plt.imshow(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The input image"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first layer filters, `conv1`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the parameters are a list of [weights, biases]\n",
      "filters = net.params['conv1'][0].data\n",
      "vis_square(filters.transpose(0, 2, 3, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first layer output, `conv1` (rectified responses of the filters above, first 36 only)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['conv1'].data[0, :36]\n",
      "vis_square(feat, padval=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second layer filters, `conv2`\n",
      "\n",
      "There are 256 filters, each of which has dimension 5 x 5 x 48. We show only the first 48 filters, with each channel shown separately, so that each filter is a row."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filters = net.params['conv2'][0].data\n",
      "vis_square(filters[:48].reshape(48**2, 5, 5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second layer output, `conv2` (rectified, only the first 36 of 256 channels)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['conv2'].data[0, :36]\n",
      "vis_square(feat, padval=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The third layer output, `conv3` (rectified, all 384 channels)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['conv3'].data[0]\n",
      "vis_square(feat, padval=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The fourth layer output, `conv4` (rectified, all 384 channels)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['conv4'].data[0]\n",
      "vis_square(feat, padval=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The fifth layer output, `conv5` (rectified, all 256 channels)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['conv5'].data[0]\n",
      "vis_square(feat, padval=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The fifth layer after pooling, `pool5`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['pool5'].data[0]\n",
      "vis_square(feat, padval=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first fully connected layer, `fc6` (rectified)\n",
      "\n",
      "We show the output values and the histogram of the positive values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['fc6'].data[0]\n",
      "plt.subplot(2, 1, 1)\n",
      "plt.plot(feat.flat)\n",
      "plt.subplot(2, 1, 2)\n",
      "_ = plt.hist(feat.flat[feat.flat > 0], bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second fully connected layer, `fc7` (rectified)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['fc7'].data[0]\n",
      "plt.subplot(2, 1, 1)\n",
      "plt.plot(feat.flat)\n",
      "plt.subplot(2, 1, 2)\n",
      "_ = plt.hist(feat.flat[feat.flat > 0], bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The final probability output, `prob`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = net.blobs['prob'].data[0]\n",
      "plt.plot(feat.flat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see the top 5 predicted labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load labels\n",
      "imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
      "try:\n",
      "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
      "except:\n",
      "    !../data/ilsvrc12/get_ilsvrc_aux.sh\n",
      "    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
      "\n",
      "# sort top k predictions from softmax output\n",
      "top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
      "print labels[top_k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
