// AUTOMATICALLY GENERATED FILE, DO NOT EDIT
#ifdef USE_GREENTEA
#include "caffe/greentea/cl_kernels.hpp"
#include <sstream>
#include <string>
namespace caffe {
std::string header = "#ifndef __OPENCL_VERSION__\n#define __kernel\n#define __global\n#define __constant\n#define __local\n#define get_global_id(x) 0\n#define get_global_size(x) 0\n#define get_local_id(x) 0\n#define get_local_size(x) 0\n#define FLT_MAX 0\n#define FLT_MIN 0\n#define cl_khr_fp64\n#define cl_amd_fp64\n#define DOUBLE_SUPPORT_AVAILABLE\n#define CLK_LOCAL_MEM_FENCE\n#define Dtype float\n#define barrier(x)\n#endif\n\n#define CONCAT(A,B) A##_##B\n#define TEMPLATE(name,type) CONCAT(name,type)\n\n\n#if defined(cl_khr_fp64)\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#define DOUBLE_SUPPORT_AVAILABLE\n#elif defined(cl_amd_fp64)\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#define DOUBLE_SUPPORT_AVAILABLE\n#endif";
std::string header_float = "#ifndef __OPENCL_VERSION__\n#define __kernel\n#define __global\n#define __constant\n#define __local\n#define get_global_id(x) 0\n#define get_global_size(x) 0\n#define get_local_id(x) 0\n#define get_local_size(x) 0\n#define FLT_MAX 0\n#define FLT_MIN 0\n#define cl_khr_fp64\n#define cl_amd_fp64\n#define DOUBLE_SUPPORT_AVAILABLE\n#define CLK_LOCAL_MEM_FENCE\n#define Dtype float\n#define barrier(x)\n#endif\n\n#define CONCAT(A,B) A##_##B\n#define TEMPLATE(name,type) CONCAT(name,type)\n\n\n#if defined(cl_khr_fp64)\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#define DOUBLE_SUPPORT_AVAILABLE\n#elif defined(cl_amd_fp64)\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#define DOUBLE_SUPPORT_AVAILABLE\n#endif";
std::string activation_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(relu_forward,Dtype)(const int n, __global const Dtype* in,\n                             __global Dtype* out, Dtype negative_slope) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    out[index] = in[index] > 0 ? in[index] : in[index] * negative_slope;\n  }\n}";
std::string auxiliary_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(gpu_set,Dtype)(const int n, const Dtype alpha, __global Dtype* y) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index] = alpha;\n  }\n}";
std::string channel_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(kernel_channel_max,Dtype)(const int num, const int channels,\n                                   const int spatial_dim,\n                                   __global const Dtype* data,\n                                   __global Dtype* out) {\n  for (int index = get_global_id(0); index < num * spatial_dim; index +=\n      get_global_size(0)) {\n    int n = index / spatial_dim;\n    int s = index % spatial_dim;\n    float maxval = -FLT_MAX;\n    for (int c = 0; c < channels; ++c) {\n      maxval = max((Dtype)(data[(n * channels + c) * spatial_dim + s]), (Dtype)maxval);\n    }\n    out[index] = maxval;\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_subtract,Dtype)(const int count, const int num,\n                                        const int channels,\n                                        const int spatial_dim,\n                                        __global const Dtype* channel_max,\n                                        __global Dtype* data) {\n  for (int index = get_global_id(0); index < count;\n      index += get_global_size(0)) {\n    int n = index / channels / spatial_dim;\n    int s = index % spatial_dim;\n    data[index] -= channel_max[n * spatial_dim + s];\n  }\n}\n\n__kernel void TEMPLATE(kernel_exp,Dtype)(const int count, __global const Dtype* data,\n                           __global Dtype* out) {\n  for (int index = get_global_id(0); index < count;\n      index += get_global_size(0)) {\n    out[index] = exp(data[index]);\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_sum,Dtype)(const int num, const int channels,\n                                   const int spatial_dim,\n                                   __global const Dtype* data,\n                                   __global Dtype* channel_sum) {\n  for (int index = get_global_id(0); index < num * spatial_dim; index +=\n      get_global_size(0)) {\n    int n = index / spatial_dim;\n    int s = index % spatial_dim;\n    Dtype sum = 0;\n    for (int c = 0; c < channels; ++c) {\n      sum += data[(n * channels + c) * spatial_dim + s];\n    }\n    channel_sum[index] = sum;\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_div,Dtype)(const int count, const int num,\n                                   const int channels, const int spatial_dim,\n                                   __global const Dtype* channel_sum,\n                                   __global Dtype* data) {\n  for (int index = get_global_id(0); index < count;\n      index += get_global_size(0)) {\n    int n = index / channels / spatial_dim;\n    int s = index % spatial_dim;\n    data[index] /= channel_sum[n * spatial_dim + s];\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_dot,Dtype)(const int num, const int channels,\n                                   const int spatial_dim,\n                                   __global const Dtype* data_1,\n                                   __global const Dtype* data_2,\n                                   __global Dtype* channel_dot) {\n  for (int index = get_global_id(0); index < num * spatial_dim; index +=\n      get_global_size(0)) {\n    int n = index / spatial_dim;\n    int s = index % spatial_dim;\n    Dtype dot = 0;\n    for (int c = 0; c < channels; ++c) {\n      dot += (data_1[(n * channels + c) * spatial_dim + s]\n          * data_2[(n * channels + c) * spatial_dim + s]);\n    }\n    channel_dot[index] = dot;\n  }\n}";
std::string convolution_sk_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n/*__kernel void TEMPLATE(convolution_ip4v3,Dtype)(__global const Dtype *w,\n                                                __global const Dtype *in,\n                                                __global Dtype *out) {\n\n  const int width = 200;\n  const int height = 200;\n  const int kernel_h = 10;\n  const int kernel_w = 10;\n  const int fout_count = 1024;\n  const int fin_count = 192;\n  const int kstride_h = 8;\n  const int kstride_w = 8;\n  const int stride_h = 1;\n  const int stride_w = 1;\n  const int batch_size = 1;\n  const int buff_w = 73;\n  const int buff_h = 73;\n\n  const int ext_kernel_h = (kernel_h - 1) * kstride_h + 1;\n  const int ext_kernel_w = (kernel_w - 1) * kstride_w + 1;\n\n  const int out_h = (height - ext_kernel_h) / stride_h + 1;\n  const int out_w = (width - ext_kernel_w) / stride_w + 1;\n\n  // Clear the output\n  {\n#pragma unroll 1\n    for (int i =\n        get_global_id(\n            0)+get_global_id(1)*get_global_size(0)+get_global_id(2)*get_global_size(0)*get_global_size(1);\n        i < fout_count * out_h * out_w;\n        i += get_global_size(0) * get_global_size(1) * get_global_size(2)) {\n      out[i] = 0.0;\n    }\n  }\n\n  // Local weight buffer (in local memory)\n  __local Dtype wl[10 * 10];\n  // Local input buffer (in local memory)\n  __local Dtype il[73 * 73];\n  // Local accumulators (in registers)\n  Dtype al[2 * 2];\n\n  // Across output features\n#pragma unroll 1\n  for (int fout = get_global_id(2); fout < fout_count;\n      fout += get_global_size(2)) {\n\n    // Across input features\n#pragma unroll 1\n    for (int fin = 0; fin < fin_count; ++fin) {\n\n      // Load local weights\n#pragma unroll 1\n      for (int i = get_local_id(1); i < kernel_h; i += get_local_size(1)) {\n#pragma unroll 1\n        for (int j = get_local_id(0); j < kernel_w; j += get_local_size(0)) {\n          wl[j + i * kernel_w] = w[j + i * kernel_w\n              + fout * fin_count * kernel_h * kernel_w\n              + fin * kernel_h * kernel_w];\n        }\n      }\n\n      // Across batches (keeps weights in local memory)\n#pragma unroll 1\n      for (int batch = 0; batch < batch_size; ++batch) {\n\n        const int batch_in_off = batch * width * height * fin_count;\n        const int batch_out_off = batch * out_w * out_h * fout_count;\n\n        // Shift the patch window across width and height\n        for (int yoff = 0; yoff < height; yoff += buff_h) {\n          for (int xoff = 0; xoff < width; xoff += buff_w) {\n\n            // Load image patch\n#pragma unroll 1\n            for (int i = get_local_id(1); i < buff_h; i += get_local_size(1)) {\n#pragma unroll 1\n              for (int j = get_local_id(0); j < buff_w;\n                  j += get_local_size(0)) {\n                int xidx = (j + xoff);\n                int yidx = (i + yoff);\n                if (xidx < width && yidx < height) {\n                  il[j + i * buff_w] = in[xidx + yidx * width\n                      + fin * width * height + batch_in_off];\n                }\n              }\n            }\n\n            barrier(CLK_LOCAL_MEM_FENCE);\n\n            // Kernel inner loop\n#pragma unroll 1\n            for (int i = get_local_id(1); i < buff_h; i += get_local_size(1)) {\n#pragma unroll 1\n              for (int j = get_local_id(0); j < buff_w;\n                  j += get_local_size(0)) {\n\n                // Load accumulators\n#pragma unroll 1\n                for (int k = 0; k < 4; k++) {\n                  int xidx = (j + xoff - k % 2 * buff_w);\n                  int yidx = (i + yoff - k / 2 * buff_h);\n                  if (xidx >= 0 && xidx < out_w && yidx >= 0 && yidx < out_h) {\n                    al[k] = out[xidx + yidx * out_w + fout * out_w * out_h\n                        + batch_out_off];\n                  }\n                }\n\n#pragma unroll 2\n                for (int ki = 0; ki < kernel_h; ++ki) {\n#pragma unroll 2\n                  for (int kj = 0; kj < kernel_w; ++kj) {\n                    al[(j + kj * kstride_w) / buff_w + (i + ki * kstride_h) / buff_h * 2] +=\n                        wl[kj + ki * kernel_w]\n                            * il[(j + kj * kstride_w) % buff_w\n                                + ((i + ki * kstride_h) % buff_h) * buff_w];\n                  }\n                }\n\n                // Store accumulators\n#pragma unroll 1\n                for (int k = 0; k < 4; k++) {\n                  int xidx = (j + xoff - k % 2 * buff_w);\n                  int yidx = (i + yoff - k / 2 * buff_h);\n                  if (xidx >= 0 && xidx < out_w && yidx >= 0 && yidx < out_h) {\n                    out[xidx + yidx * out_w + fout * out_w * out_h\n                        + batch_out_off] = al[k];\n                  }\n                }\n              }\n            }barrier(CLK_LOCAL_MEM_FENCE);\n          }\n        }\n      }\n    }\n  }\n}\n\n// Fits into 32 KB\n__kernel void TEMPLATE(convolution_ip4v2,Dtype)(__global const Dtype *w,\n                                                __global const Dtype *in,\n                                                __global Dtype *out) {\n  const int width = 200;\n  const int height = 200;\n  const int kernel_h = 10;\n  const int kernel_w = 10;\n  const int fout_count = 1024;\n  const int fin_count = 192;\n  const int kstride_h = 8;\n  const int kstride_w = 8;\n  const int stride_h = 1;\n  const int stride_w = 1;\n  const int batch_size = 1;\n\n  const int ext_kernel_h = (kernel_h - 1) * kstride_h + 1;\n  const int ext_kernel_w = (kernel_w - 1) * kstride_w + 1;\n\n  const int out_h = (height - ext_kernel_h) / stride_h + 1;\n  const int out_w = (width - ext_kernel_w) / stride_w + 1;\n\n  // Clear the output\n  {\n#pragma unroll 1\n    for (int i =\n        get_global_id(\n            0)+get_global_id(1)*get_global_size(0)+get_global_id(2)*get_global_size(0)*get_global_size(1);\n        i < fout_count * out_h * out_w;\n        i += get_global_size(0) * get_global_size(1) * get_global_size(2)) {\n      out[i] = 0.0;\n    }\n  }\n\n  // Local weight buffer\n  __local Dtype wl[10 * 10];\n\n  // Across output features\n#pragma unroll 1\n  for (int fout = get_global_id(2); fout < fout_count;\n      fout += get_global_size(2)) {\n\n    // Across input features\n#pragma unroll 1\n    for (int fin = 0; fin < fin_count; ++fin) {\n\n      // Load local weights\n#pragma unroll 1\n      for (int i = get_local_id(1); i < kernel_h; i += get_local_size(1)) {\n#pragma unroll 1\n        for (int j = get_local_id(0); j < kernel_w; j += get_local_size(0)) {\n          wl[j + i * kernel_w] = w[j + i * kernel_w\n              + fout * fin_count * kernel_h * kernel_w\n              + fin * kernel_h * kernel_w];\n        }\n      }\n\n      barrier(CLK_LOCAL_MEM_FENCE);\n\n      // Across batches (keeps weights in local memory)\n#pragma unroll 1\n      for (int batch = 0; batch < batch_size; ++batch) {\n\n        const int batch_in_off = batch * width * height * fin_count;\n        const int batch_out_off = batch * out_w * out_h * fout_count;\n\n        // Across y-dimension\n#pragma unroll 1\n        for (int yoff = get_global_id(1); yoff < height - ext_kernel_h + 1;\n            yoff += get_global_size(1)) {\n\n          // Across x-dimension\n#pragma unroll 1\n          for (int xoff = get_global_id(0); xoff < width - ext_kernel_w + 1;\n              xoff += get_global_size(0)) {\n\n            Dtype outval = out[xoff + yoff * out_w + fout * out_w * out_h\n                + batch_out_off];\n\n            // Across the kernel itself\n#pragma unroll 1\n            for (int i = 0; i < kernel_h; ++i) {\n#pragma unroll 1\n              for (int j = 0; j < kernel_w; ++j) {\n                outval = fma(\n                    wl[j + i * kernel_w],\n                    in[(xoff + j * kstride_w) + (yoff + i * kstride_h) * width\n                        + fin * width * height + batch_in_off],\n                    outval);\n              }\n            }\n\n            out[xoff + yoff * out_w + fout * out_w * out_h + batch_out_off] =\n                outval;\n          }\n        }\n      }barrier(CLK_LOCAL_MEM_FENCE);\n    }\n  }\n}*/";
std::string im2col_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif";
std::string im2col_sk_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(im2col_sk,Dtype)(const int n,\n                                        __global const Dtype* data_im,\n                                        const int data_offset, const int height,\n                                        const int width, const int kernel_h,\n                                        const int kernel_w,\n                                        const int ext_kernel_h,\n                                        const int ext_kernel_w, const int pad_h,\n                                        const int pad_w, const int stride_h,\n                                        const int stride_w, const int kstride_h,\n                                        const int kstride_w,\n                                        const int height_col,\n                                        const int width_col,\n                                        __global Dtype* data_col) {\n\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    int w_out = index % width_col;\n    int h_index = index / width_col;\n    int h_out = h_index % height_col;\n    int channel_in = h_index / height_col;\n    int channel_out = channel_in * kernel_h * kernel_w;\n    int h_in = h_out * stride_h - pad_h;\n    int w_in = w_out * stride_w - pad_w;\n    __global Dtype* data_col_ptr = data_col;\n    data_col_ptr += (channel_out * height_col + h_out) * width_col + w_out;\n    __global const Dtype* data_im_ptr = data_im + data_offset;\n    data_im_ptr += (channel_in * height + h_in) * width + w_in;\n    for (int i = 0; i < ext_kernel_h; i += kstride_h) {\n      for (int j = 0; j < ext_kernel_w; j += kstride_w) {\n        int h = h_in + i;\n        int w = w_in + j;\n        (*data_col_ptr) =\n            (h >= 0 && w >= 0 && h < height && w < width) ?\n                data_im_ptr[i * width + j] : 0;\n        data_col_ptr += height_col * width_col;\n      }\n    }\n  }\n\n}\n\n__kernel void TEMPLATE(col2im_sk,Dtype)(const int n, __global const Dtype* data_col,\n                                        const int height, const int width,\n                                        const int channels, const int patch_h,\n                                        const int patch_w,\n                                        const int ext_patch_h,\n                                        const int ext_patch_w, const int pad_h,\n                                        const int pad_w, const int stride_h,\n                                        const int stride_w, const int kstride_h,\n                                        const int kstride_w,\n                                        const int height_col,\n                                        const int width_col,\n                                        __global Dtype* data_im, const int data_offset) {\n\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    Dtype val = 0;\n    int w = index % width + pad_w;\n    int h = (index / width) % height + pad_h;\n    int c = index / (width * height);\n    // compute the start and end of the output\n    int width_col_1 = width_col - 1;\n    int height_col_1 = height_col - 1;\n    int w_col_start = (w < ext_patch_w) ? w % kstride_w : (w - ext_patch_w) + 1;\n    int w_col_end =\n        (w >= width_col) ?\n            width_col_1 - (width_col_1 - w_col_start) % kstride_w : w;\n    int h_col_start = (h < ext_patch_h) ? h % kstride_h : (h - ext_patch_h) + 1;\n    int h_col_end =\n        (h >= height_col) ?\n            height_col_1 - (height_col_1 - h_col_start) % kstride_h : h;\n    int w_num = (w - w_col_start) / kstride_w;\n    int h_num = (h - h_col_start) / kstride_h;\n\n    int coeff_w_idx = height_col * width_col;\n    int coeff_h_idx = patch_w * coeff_w_idx;\n    int offset = c * patch_h * coeff_h_idx;\n    for (int h_col = h_col_start, h_idx = h_num; h_col <= h_col_end; h_col +=\n        kstride_h, --h_idx) {\n      for (int w_col = w_col_start, w_idx = w_num; w_col <= w_col_end; w_col +=\n          kstride_w, --w_idx) {\n        //int c_col = c * patch_h * patch_w + (h - h_col) / kstride_h * patch_w + (w - w_col) / kstride_w;\n        //int c_col = c * patch_h * patch_w + h_idx * patch_w + w_idx;\n        //val += data_col[(c_col * height_col + h_col) * width_col + w_col];\n        val += data_col[offset + h_idx * coeff_h_idx + w_idx * coeff_w_idx\n            + h_col * width_col + w_col];\n      }\n    }\n\n    data_im[data_offset + index] = val;\n  }\n}";
std::string math_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(mul,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa,\n                                  __global Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = a[index + offa] * b[index + offb];\n  }\n}\n\n__kernel void TEMPLATE(div,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa,\n                                  __global Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = a[index + offa] / b[index + offb];\n  }\n}\n\n__kernel void TEMPLATE(add_scalar,Dtype)(const int N, const Dtype alpha,\n__global Dtype* Y,\n                                         const int offY) {\n  for (int index = get_global_id(0); index < N; index += get_global_size(0)) {\n    Y[offY + index] += alpha;\n  }\n}\n\n__kernel void TEMPLATE(add,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global const Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = a[offa + index] + b[offb + index];\n  }\n}\n\n__kernel void TEMPLATE(sub,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global const Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = a[offa + index] - b[offb + index];\n  }\n}\n\n__kernel void TEMPLATE(abs,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = fabs((Dtype)(a[offa + index]));\n  }\n}\n\n__kernel void TEMPLATE(exp,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = exp(a[offa + index]);\n  }\n}\n\n__kernel void TEMPLATE(powx,Dtype)(const int n, __global const Dtype* a,\n                                   const int offa, Dtype alpha,\n                                   __global Dtype* y,\n                                   const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = pow(a[offa + index], alpha);\n  }\n}\n\n__kernel void TEMPLATE(sign,Dtype)(const int n, __global const Dtype* x,\n                                   const int offx, __global Dtype* y,\n                                   const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = (0.0 < x[index + offx])\n        - (x[index + offx] < 0.0);\n  }\n}\n\n__kernel void TEMPLATE(sgnbit,Dtype)(const int n, __global const Dtype* x,\n                                     const int offx, __global Dtype* y,\n                                     const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = signbit(x[index + offx]);\n  }\n}";
std::string pooling_sk_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(max_pool_forward_sk,Dtype)(const int nthreads,\n                                    __global Dtype* bottom_data,\n                                    const int num, const int channels,\n                                    const int height, const int width,\n                                    const int pooled_height,\n                                    const int pooled_width, const int kernel_h,\n                                    const int kernel_w, const int ext_kernel_h,\n                                    const int ext_kernel_w, const int stride_h,\n                                    const int stride_w, const int kstride_h,\n                                    const int kstride_w, const int pad_h,\n                                    const int pad_w, __global Dtype* top_data,\n                                    const int use_mask,\n                                    __global int* mask,\n                                    __global Dtype* top_mask) {\n  for (int index = get_global_id(0); index < nthreads;\n      index += get_global_size(0)) {\n    int pw = index % pooled_width;\n    int ph = (index / pooled_width) % pooled_height;\n    int c = (index / pooled_width / pooled_height) % channels;\n    int n = index / pooled_width / pooled_height / channels;\n    int hstart = ph * stride_h - pad_h;\n    int wstart = pw * stride_w - pad_w;\n    int hend = min(hstart + ext_kernel_h, height);\n    int wend = min(wstart + ext_kernel_w, width);\n    hstart = max(hstart, (int)0);\n    wstart = max(wstart, (int)0);\n    Dtype maxval = -FLT_MAX;\n    int maxidx = -1;\n    __global Dtype* bottom_data_ptr = bottom_data + (n * channels + c) * height * width;\n    for (int h = hstart; h < hend; h += kstride_h) {\n      for (int w = wstart; w < wend; w += kstride_w) {\n        if (bottom_data_ptr[h * width + w] > maxval) {\n          maxidx = h * width + w;\n          maxval = bottom_data_ptr[maxidx];\n        }\n      }\n    }\n    top_data[index] = maxval;\n    if (use_mask == 1) {\n      mask[index] = maxidx;\n    } else {\n      top_mask[index] = maxidx;\n    }\n  }\n}";
std::string softmax_loss_float = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(softmax_loss_forward_gpu,Dtype)(int n, __global const Dtype* prob_data,\n                                         __global const Dtype* label,\n                                         __global Dtype* loss, const int num,\n                                         const int dim, const int spatial_dim,\n                                         const int has_ignore_label_,\n                                         const int ignore_label_,\n                                         __global Dtype* counts) {\n\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    const int n = index / spatial_dim;\n    const int s = index % spatial_dim;\n    const int label_value = (int) (label[n * spatial_dim + s]);\n    if (has_ignore_label_ == 1 && label_value == ignore_label_) {\n      loss[index] = 0;\n      counts[index] = 0;\n    } else {\n      loss[index] = -log(\n          max((Dtype)(prob_data[n * dim + label_value * spatial_dim + s]),\n          (Dtype)FLT_MIN));\n      counts[index] = 1;\n    }\n  }\n}";
std::string activation_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(relu_forward,Dtype)(const int n, __global const Dtype* in,\n                             __global Dtype* out, Dtype negative_slope) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    out[index] = in[index] > 0 ? in[index] : in[index] * negative_slope;\n  }\n}";
std::string auxiliary_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(gpu_set,Dtype)(const int n, const Dtype alpha, __global Dtype* y) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index] = alpha;\n  }\n}";
std::string channel_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(kernel_channel_max,Dtype)(const int num, const int channels,\n                                   const int spatial_dim,\n                                   __global const Dtype* data,\n                                   __global Dtype* out) {\n  for (int index = get_global_id(0); index < num * spatial_dim; index +=\n      get_global_size(0)) {\n    int n = index / spatial_dim;\n    int s = index % spatial_dim;\n    float maxval = -FLT_MAX;\n    for (int c = 0; c < channels; ++c) {\n      maxval = max((Dtype)(data[(n * channels + c) * spatial_dim + s]), (Dtype)maxval);\n    }\n    out[index] = maxval;\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_subtract,Dtype)(const int count, const int num,\n                                        const int channels,\n                                        const int spatial_dim,\n                                        __global const Dtype* channel_max,\n                                        __global Dtype* data) {\n  for (int index = get_global_id(0); index < count;\n      index += get_global_size(0)) {\n    int n = index / channels / spatial_dim;\n    int s = index % spatial_dim;\n    data[index] -= channel_max[n * spatial_dim + s];\n  }\n}\n\n__kernel void TEMPLATE(kernel_exp,Dtype)(const int count, __global const Dtype* data,\n                           __global Dtype* out) {\n  for (int index = get_global_id(0); index < count;\n      index += get_global_size(0)) {\n    out[index] = exp(data[index]);\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_sum,Dtype)(const int num, const int channels,\n                                   const int spatial_dim,\n                                   __global const Dtype* data,\n                                   __global Dtype* channel_sum) {\n  for (int index = get_global_id(0); index < num * spatial_dim; index +=\n      get_global_size(0)) {\n    int n = index / spatial_dim;\n    int s = index % spatial_dim;\n    Dtype sum = 0;\n    for (int c = 0; c < channels; ++c) {\n      sum += data[(n * channels + c) * spatial_dim + s];\n    }\n    channel_sum[index] = sum;\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_div,Dtype)(const int count, const int num,\n                                   const int channels, const int spatial_dim,\n                                   __global const Dtype* channel_sum,\n                                   __global Dtype* data) {\n  for (int index = get_global_id(0); index < count;\n      index += get_global_size(0)) {\n    int n = index / channels / spatial_dim;\n    int s = index % spatial_dim;\n    data[index] /= channel_sum[n * spatial_dim + s];\n  }\n}\n\n__kernel void TEMPLATE(kernel_channel_dot,Dtype)(const int num, const int channels,\n                                   const int spatial_dim,\n                                   __global const Dtype* data_1,\n                                   __global const Dtype* data_2,\n                                   __global Dtype* channel_dot) {\n  for (int index = get_global_id(0); index < num * spatial_dim; index +=\n      get_global_size(0)) {\n    int n = index / spatial_dim;\n    int s = index % spatial_dim;\n    Dtype dot = 0;\n    for (int c = 0; c < channels; ++c) {\n      dot += (data_1[(n * channels + c) * spatial_dim + s]\n          * data_2[(n * channels + c) * spatial_dim + s]);\n    }\n    channel_dot[index] = dot;\n  }\n}";
std::string convolution_sk_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n/*__kernel void TEMPLATE(convolution_ip4v3,Dtype)(__global const Dtype *w,\n                                                __global const Dtype *in,\n                                                __global Dtype *out) {\n\n  const int width = 200;\n  const int height = 200;\n  const int kernel_h = 10;\n  const int kernel_w = 10;\n  const int fout_count = 1024;\n  const int fin_count = 192;\n  const int kstride_h = 8;\n  const int kstride_w = 8;\n  const int stride_h = 1;\n  const int stride_w = 1;\n  const int batch_size = 1;\n  const int buff_w = 73;\n  const int buff_h = 73;\n\n  const int ext_kernel_h = (kernel_h - 1) * kstride_h + 1;\n  const int ext_kernel_w = (kernel_w - 1) * kstride_w + 1;\n\n  const int out_h = (height - ext_kernel_h) / stride_h + 1;\n  const int out_w = (width - ext_kernel_w) / stride_w + 1;\n\n  // Clear the output\n  {\n#pragma unroll 1\n    for (int i =\n        get_global_id(\n            0)+get_global_id(1)*get_global_size(0)+get_global_id(2)*get_global_size(0)*get_global_size(1);\n        i < fout_count * out_h * out_w;\n        i += get_global_size(0) * get_global_size(1) * get_global_size(2)) {\n      out[i] = 0.0;\n    }\n  }\n\n  // Local weight buffer (in local memory)\n  __local Dtype wl[10 * 10];\n  // Local input buffer (in local memory)\n  __local Dtype il[73 * 73];\n  // Local accumulators (in registers)\n  Dtype al[2 * 2];\n\n  // Across output features\n#pragma unroll 1\n  for (int fout = get_global_id(2); fout < fout_count;\n      fout += get_global_size(2)) {\n\n    // Across input features\n#pragma unroll 1\n    for (int fin = 0; fin < fin_count; ++fin) {\n\n      // Load local weights\n#pragma unroll 1\n      for (int i = get_local_id(1); i < kernel_h; i += get_local_size(1)) {\n#pragma unroll 1\n        for (int j = get_local_id(0); j < kernel_w; j += get_local_size(0)) {\n          wl[j + i * kernel_w] = w[j + i * kernel_w\n              + fout * fin_count * kernel_h * kernel_w\n              + fin * kernel_h * kernel_w];\n        }\n      }\n\n      // Across batches (keeps weights in local memory)\n#pragma unroll 1\n      for (int batch = 0; batch < batch_size; ++batch) {\n\n        const int batch_in_off = batch * width * height * fin_count;\n        const int batch_out_off = batch * out_w * out_h * fout_count;\n\n        // Shift the patch window across width and height\n        for (int yoff = 0; yoff < height; yoff += buff_h) {\n          for (int xoff = 0; xoff < width; xoff += buff_w) {\n\n            // Load image patch\n#pragma unroll 1\n            for (int i = get_local_id(1); i < buff_h; i += get_local_size(1)) {\n#pragma unroll 1\n              for (int j = get_local_id(0); j < buff_w;\n                  j += get_local_size(0)) {\n                int xidx = (j + xoff);\n                int yidx = (i + yoff);\n                if (xidx < width && yidx < height) {\n                  il[j + i * buff_w] = in[xidx + yidx * width\n                      + fin * width * height + batch_in_off];\n                }\n              }\n            }\n\n            barrier(CLK_LOCAL_MEM_FENCE);\n\n            // Kernel inner loop\n#pragma unroll 1\n            for (int i = get_local_id(1); i < buff_h; i += get_local_size(1)) {\n#pragma unroll 1\n              for (int j = get_local_id(0); j < buff_w;\n                  j += get_local_size(0)) {\n\n                // Load accumulators\n#pragma unroll 1\n                for (int k = 0; k < 4; k++) {\n                  int xidx = (j + xoff - k % 2 * buff_w);\n                  int yidx = (i + yoff - k / 2 * buff_h);\n                  if (xidx >= 0 && xidx < out_w && yidx >= 0 && yidx < out_h) {\n                    al[k] = out[xidx + yidx * out_w + fout * out_w * out_h\n                        + batch_out_off];\n                  }\n                }\n\n#pragma unroll 2\n                for (int ki = 0; ki < kernel_h; ++ki) {\n#pragma unroll 2\n                  for (int kj = 0; kj < kernel_w; ++kj) {\n                    al[(j + kj * kstride_w) / buff_w + (i + ki * kstride_h) / buff_h * 2] +=\n                        wl[kj + ki * kernel_w]\n                            * il[(j + kj * kstride_w) % buff_w\n                                + ((i + ki * kstride_h) % buff_h) * buff_w];\n                  }\n                }\n\n                // Store accumulators\n#pragma unroll 1\n                for (int k = 0; k < 4; k++) {\n                  int xidx = (j + xoff - k % 2 * buff_w);\n                  int yidx = (i + yoff - k / 2 * buff_h);\n                  if (xidx >= 0 && xidx < out_w && yidx >= 0 && yidx < out_h) {\n                    out[xidx + yidx * out_w + fout * out_w * out_h\n                        + batch_out_off] = al[k];\n                  }\n                }\n              }\n            }barrier(CLK_LOCAL_MEM_FENCE);\n          }\n        }\n      }\n    }\n  }\n}\n\n// Fits into 32 KB\n__kernel void TEMPLATE(convolution_ip4v2,Dtype)(__global const Dtype *w,\n                                                __global const Dtype *in,\n                                                __global Dtype *out) {\n  const int width = 200;\n  const int height = 200;\n  const int kernel_h = 10;\n  const int kernel_w = 10;\n  const int fout_count = 1024;\n  const int fin_count = 192;\n  const int kstride_h = 8;\n  const int kstride_w = 8;\n  const int stride_h = 1;\n  const int stride_w = 1;\n  const int batch_size = 1;\n\n  const int ext_kernel_h = (kernel_h - 1) * kstride_h + 1;\n  const int ext_kernel_w = (kernel_w - 1) * kstride_w + 1;\n\n  const int out_h = (height - ext_kernel_h) / stride_h + 1;\n  const int out_w = (width - ext_kernel_w) / stride_w + 1;\n\n  // Clear the output\n  {\n#pragma unroll 1\n    for (int i =\n        get_global_id(\n            0)+get_global_id(1)*get_global_size(0)+get_global_id(2)*get_global_size(0)*get_global_size(1);\n        i < fout_count * out_h * out_w;\n        i += get_global_size(0) * get_global_size(1) * get_global_size(2)) {\n      out[i] = 0.0;\n    }\n  }\n\n  // Local weight buffer\n  __local Dtype wl[10 * 10];\n\n  // Across output features\n#pragma unroll 1\n  for (int fout = get_global_id(2); fout < fout_count;\n      fout += get_global_size(2)) {\n\n    // Across input features\n#pragma unroll 1\n    for (int fin = 0; fin < fin_count; ++fin) {\n\n      // Load local weights\n#pragma unroll 1\n      for (int i = get_local_id(1); i < kernel_h; i += get_local_size(1)) {\n#pragma unroll 1\n        for (int j = get_local_id(0); j < kernel_w; j += get_local_size(0)) {\n          wl[j + i * kernel_w] = w[j + i * kernel_w\n              + fout * fin_count * kernel_h * kernel_w\n              + fin * kernel_h * kernel_w];\n        }\n      }\n\n      barrier(CLK_LOCAL_MEM_FENCE);\n\n      // Across batches (keeps weights in local memory)\n#pragma unroll 1\n      for (int batch = 0; batch < batch_size; ++batch) {\n\n        const int batch_in_off = batch * width * height * fin_count;\n        const int batch_out_off = batch * out_w * out_h * fout_count;\n\n        // Across y-dimension\n#pragma unroll 1\n        for (int yoff = get_global_id(1); yoff < height - ext_kernel_h + 1;\n            yoff += get_global_size(1)) {\n\n          // Across x-dimension\n#pragma unroll 1\n          for (int xoff = get_global_id(0); xoff < width - ext_kernel_w + 1;\n              xoff += get_global_size(0)) {\n\n            Dtype outval = out[xoff + yoff * out_w + fout * out_w * out_h\n                + batch_out_off];\n\n            // Across the kernel itself\n#pragma unroll 1\n            for (int i = 0; i < kernel_h; ++i) {\n#pragma unroll 1\n              for (int j = 0; j < kernel_w; ++j) {\n                outval = fma(\n                    wl[j + i * kernel_w],\n                    in[(xoff + j * kstride_w) + (yoff + i * kstride_h) * width\n                        + fin * width * height + batch_in_off],\n                    outval);\n              }\n            }\n\n            out[xoff + yoff * out_w + fout * out_w * out_h + batch_out_off] =\n                outval;\n          }\n        }\n      }barrier(CLK_LOCAL_MEM_FENCE);\n    }\n  }\n}*/";
std::string im2col_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif";
std::string im2col_sk_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(im2col_sk,Dtype)(const int n,\n                                        __global const Dtype* data_im,\n                                        const int data_offset, const int height,\n                                        const int width, const int kernel_h,\n                                        const int kernel_w,\n                                        const int ext_kernel_h,\n                                        const int ext_kernel_w, const int pad_h,\n                                        const int pad_w, const int stride_h,\n                                        const int stride_w, const int kstride_h,\n                                        const int kstride_w,\n                                        const int height_col,\n                                        const int width_col,\n                                        __global Dtype* data_col) {\n\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    int w_out = index % width_col;\n    int h_index = index / width_col;\n    int h_out = h_index % height_col;\n    int channel_in = h_index / height_col;\n    int channel_out = channel_in * kernel_h * kernel_w;\n    int h_in = h_out * stride_h - pad_h;\n    int w_in = w_out * stride_w - pad_w;\n    __global Dtype* data_col_ptr = data_col;\n    data_col_ptr += (channel_out * height_col + h_out) * width_col + w_out;\n    __global const Dtype* data_im_ptr = data_im + data_offset;\n    data_im_ptr += (channel_in * height + h_in) * width + w_in;\n    for (int i = 0; i < ext_kernel_h; i += kstride_h) {\n      for (int j = 0; j < ext_kernel_w; j += kstride_w) {\n        int h = h_in + i;\n        int w = w_in + j;\n        (*data_col_ptr) =\n            (h >= 0 && w >= 0 && h < height && w < width) ?\n                data_im_ptr[i * width + j] : 0;\n        data_col_ptr += height_col * width_col;\n      }\n    }\n  }\n\n}\n\n__kernel void TEMPLATE(col2im_sk,Dtype)(const int n, __global const Dtype* data_col,\n                                        const int height, const int width,\n                                        const int channels, const int patch_h,\n                                        const int patch_w,\n                                        const int ext_patch_h,\n                                        const int ext_patch_w, const int pad_h,\n                                        const int pad_w, const int stride_h,\n                                        const int stride_w, const int kstride_h,\n                                        const int kstride_w,\n                                        const int height_col,\n                                        const int width_col,\n                                        __global Dtype* data_im, const int data_offset) {\n\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    Dtype val = 0;\n    int w = index % width + pad_w;\n    int h = (index / width) % height + pad_h;\n    int c = index / (width * height);\n    // compute the start and end of the output\n    int width_col_1 = width_col - 1;\n    int height_col_1 = height_col - 1;\n    int w_col_start = (w < ext_patch_w) ? w % kstride_w : (w - ext_patch_w) + 1;\n    int w_col_end =\n        (w >= width_col) ?\n            width_col_1 - (width_col_1 - w_col_start) % kstride_w : w;\n    int h_col_start = (h < ext_patch_h) ? h % kstride_h : (h - ext_patch_h) + 1;\n    int h_col_end =\n        (h >= height_col) ?\n            height_col_1 - (height_col_1 - h_col_start) % kstride_h : h;\n    int w_num = (w - w_col_start) / kstride_w;\n    int h_num = (h - h_col_start) / kstride_h;\n\n    int coeff_w_idx = height_col * width_col;\n    int coeff_h_idx = patch_w * coeff_w_idx;\n    int offset = c * patch_h * coeff_h_idx;\n    for (int h_col = h_col_start, h_idx = h_num; h_col <= h_col_end; h_col +=\n        kstride_h, --h_idx) {\n      for (int w_col = w_col_start, w_idx = w_num; w_col <= w_col_end; w_col +=\n          kstride_w, --w_idx) {\n        //int c_col = c * patch_h * patch_w + (h - h_col) / kstride_h * patch_w + (w - w_col) / kstride_w;\n        //int c_col = c * patch_h * patch_w + h_idx * patch_w + w_idx;\n        //val += data_col[(c_col * height_col + h_col) * width_col + w_col];\n        val += data_col[offset + h_idx * coeff_h_idx + w_idx * coeff_w_idx\n            + h_col * width_col + w_col];\n      }\n    }\n\n    data_im[data_offset + index] = val;\n  }\n}";
std::string math_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(mul,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa,\n                                  __global Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = a[index + offa] * b[index + offb];\n  }\n}\n\n__kernel void TEMPLATE(div,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa,\n                                  __global Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = a[index + offa] / b[index + offb];\n  }\n}\n\n__kernel void TEMPLATE(add_scalar,Dtype)(const int N, const Dtype alpha,\n__global Dtype* Y,\n                                         const int offY) {\n  for (int index = get_global_id(0); index < N; index += get_global_size(0)) {\n    Y[offY + index] += alpha;\n  }\n}\n\n__kernel void TEMPLATE(add,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global const Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = a[offa + index] + b[offb + index];\n  }\n}\n\n__kernel void TEMPLATE(sub,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global const Dtype* b,\n                                  const int offb, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = a[offa + index] - b[offb + index];\n  }\n}\n\n__kernel void TEMPLATE(abs,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = fabs((Dtype)(a[offa + index]));\n  }\n}\n\n__kernel void TEMPLATE(exp,Dtype)(const int n, __global const Dtype* a,\n                                  const int offa, __global Dtype* y,\n                                  const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = exp(a[offa + index]);\n  }\n}\n\n__kernel void TEMPLATE(powx,Dtype)(const int n, __global const Dtype* a,\n                                   const int offa, Dtype alpha,\n                                   __global Dtype* y,\n                                   const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[offy + index] = pow(a[offa + index], alpha);\n  }\n}\n\n__kernel void TEMPLATE(sign,Dtype)(const int n, __global const Dtype* x,\n                                   const int offx, __global Dtype* y,\n                                   const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = (0.0 < x[index + offx])\n        - (x[index + offx] < 0.0);\n  }\n}\n\n__kernel void TEMPLATE(sgnbit,Dtype)(const int n, __global const Dtype* x,\n                                     const int offx, __global Dtype* y,\n                                     const int offy) {\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    y[index + offy] = signbit(x[index + offx]);\n  }\n}";
std::string pooling_sk_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(max_pool_forward_sk,Dtype)(const int nthreads,\n                                    __global Dtype* bottom_data,\n                                    const int num, const int channels,\n                                    const int height, const int width,\n                                    const int pooled_height,\n                                    const int pooled_width, const int kernel_h,\n                                    const int kernel_w, const int ext_kernel_h,\n                                    const int ext_kernel_w, const int stride_h,\n                                    const int stride_w, const int kstride_h,\n                                    const int kstride_w, const int pad_h,\n                                    const int pad_w, __global Dtype* top_data,\n                                    const int use_mask,\n                                    __global int* mask,\n                                    __global Dtype* top_mask) {\n  for (int index = get_global_id(0); index < nthreads;\n      index += get_global_size(0)) {\n    int pw = index % pooled_width;\n    int ph = (index / pooled_width) % pooled_height;\n    int c = (index / pooled_width / pooled_height) % channels;\n    int n = index / pooled_width / pooled_height / channels;\n    int hstart = ph * stride_h - pad_h;\n    int wstart = pw * stride_w - pad_w;\n    int hend = min(hstart + ext_kernel_h, height);\n    int wend = min(wstart + ext_kernel_w, width);\n    hstart = max(hstart, (int)0);\n    wstart = max(wstart, (int)0);\n    Dtype maxval = -FLT_MAX;\n    int maxidx = -1;\n    __global Dtype* bottom_data_ptr = bottom_data + (n * channels + c) * height * width;\n    for (int h = hstart; h < hend; h += kstride_h) {\n      for (int w = wstart; w < wend; w += kstride_w) {\n        if (bottom_data_ptr[h * width + w] > maxval) {\n          maxidx = h * width + w;\n          maxval = bottom_data_ptr[maxidx];\n        }\n      }\n    }\n    top_data[index] = maxval;\n    if (use_mask == 1) {\n      mask[index] = maxidx;\n    } else {\n      top_mask[index] = maxidx;\n    }\n  }\n}";
std::string softmax_loss_double = "#ifndef __OPENCL_VERSION__\n#include \"header.cl\"\n#endif\n\n__kernel void TEMPLATE(softmax_loss_forward_gpu,Dtype)(int n, __global const Dtype* prob_data,\n                                         __global const Dtype* label,\n                                         __global Dtype* loss, const int num,\n                                         const int dim, const int spatial_dim,\n                                         const int has_ignore_label_,\n                                         const int ignore_label_,\n                                         __global Dtype* counts) {\n\n  for (int index = get_global_id(0); index < n; index += get_global_size(0)) {\n    const int n = index / spatial_dim;\n    const int s = index % spatial_dim;\n    const int label_value = (int) (label[n * spatial_dim + s]);\n    if (has_ignore_label_ == 1 && label_value == ignore_label_) {\n      loss[index] = 0;\n      counts[index] = 0;\n    } else {\n      loss[index] = -log(\n          max((Dtype)(prob_data[n * dim + label_value * spatial_dim + s]),\n          (Dtype)FLT_MIN));\n      counts[index] = 1;\n    }\n  }\n}";
viennacl::ocl::program & RegisterKernels(viennacl::ocl::context &ctx) {
  std::stringstream ss;
  ss << header << "\n\n";
  ss << "#define Dtype float" << "\n\n";
  ss << activation_float << "\n\n";
  ss << auxiliary_float << "\n\n";
  ss << channel_float << "\n\n";
  ss << convolution_sk_float << "\n\n";
  ss << im2col_float << "\n\n";
  ss << im2col_sk_float << "\n\n";
  ss << math_float << "\n\n";
  ss << pooling_sk_float << "\n\n";
  ss << softmax_loss_float << "\n\n";
#ifdef GREENTEA_DOUBLE_SUPPORT
  ss << "#ifdef DOUBLE_SUPPORT_AVAILABLE" << "\n\n";
  ss << "#undef Dtype" << "\n\n";
  ss << "#define Dtype double" << "\n\n";
  ss << activation_double << "\n\n";
  ss << auxiliary_double << "\n\n";
  ss << channel_double << "\n\n";
  ss << convolution_sk_double << "\n\n";
  ss << im2col_double << "\n\n";
  ss << im2col_sk_double << "\n\n";
  ss << math_double << "\n\n";
  ss << pooling_sk_double << "\n\n";
  ss << softmax_loss_double << "\n\n";
  ss << "#endif" << "\n\n";
#endif // GREENTEA_DOUBLE_SUUPORT
  std::string kernel_string = ss.str();
  const char* kernel_program = kernel_string.c_str();
  ctx.build_options("-cl-fast-relaxed-math -cl-mad-enable");
  viennacl::ocl::program &program = ctx.add_program(kernel_program,"kernel_program");
  return program;
}
}
#endif
